iter_count: 146
Epoch: [1]  [  0/145]  eta: 0:01:19  lr: 0.010000  loss: 1.4786 (1.4786)  loss_classifier: 0.6860 (0.6860)  loss_box_reg: 0.0238 (0.0238)  loss_objectness: 0.6926 (0.6926)  loss_rpn_box_reg: 0.0762 (0.0762)  time: 0.5457  data: 0.1871  max mem: 2617
/home/choi/anaconda3/envs/headhunter/lib/python3.8/site-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details.
  warnings.warn("The default behavior for interpolate/upsample with float scale_factor changed "
iter_count: 147
iter_count: 148
iter_count: 149
iter_count: 150
iter_count: 151
iter_count: 152
iter_count: 153
iter_count: 154
iter_count: 155
Traceback (most recent call last):
  File "train.py", line 193, in <module>
    train()
  File "train.py", line 184, in train
    train_one_epoch(model, optimizer, train_data_loader,
  File "/home/choi/hwang/workspace/HeadHunter/head_detection/vision/engine.py", line 49, in train_one_epoch
    loss_dict = model(images, targets)
  File "/home/choi/anaconda3/envs/headhunter/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/choi/anaconda3/envs/headhunter/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 619, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/home/choi/anaconda3/envs/headhunter/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/choi/anaconda3/envs/headhunter/lib/python3.8/site-packages/torchvision/models/detection/generalized_rcnn.py", line 99, in forward
    proposals, proposal_losses = self.rpn(images, features, targets)
  File "/home/choi/anaconda3/envs/headhunter/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/choi/hwang/workspace/HeadHunter/head_detection/models/fast_rcnn.py", line 495, in forward
    anchors = self.anchor_generator(images, features)
  File "/home/choi/anaconda3/envs/headhunter/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/choi/anaconda3/envs/headhunter/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py", line 147, in forward
    strides = [[torch.tensor(image_size[0] // g[0], dtype=torch.int64, device=device),
  File "/home/choi/anaconda3/envs/headhunter/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py", line 147, in <listcomp>
    strides = [[torch.tensor(image_size[0] // g[0], dtype=torch.int64, device=device),
KeyboardInterrupt
