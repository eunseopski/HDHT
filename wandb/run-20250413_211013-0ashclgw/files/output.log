Epoch: [1]  [    0/15000]  eta: 2:13:20  lr: 0.010000  loss: 1.5005 (1.5005)  loss_classifier: 0.7150 (0.7150)  loss_box_reg: 0.0000 (0.0000)  loss_objectness: 0.6933 (0.6933)  loss_rpn_box_reg: 0.0921 (0.0921)  time: 0.5334  data: 0.1799  max mem: 2548
/home/choi/anaconda3/envs/headhunter/lib/python3.8/site-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details.
  warnings.warn("The default behavior for interpolate/upsample with float scale_factor changed "
Traceback (most recent call last):
  File "train.py", line 193, in <module>
    train()
  File "train.py", line 184, in train
    train_one_epoch(model, optimizer, train_data_loader,
  File "/home/choi/hwang/workspace/HeadHunter/head_detection/vision/engine.py", line 49, in train_one_epoch
    loss_dict = model(images, targets)
  File "/home/choi/anaconda3/envs/headhunter/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/choi/anaconda3/envs/headhunter/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 619, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/home/choi/anaconda3/envs/headhunter/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/choi/anaconda3/envs/headhunter/lib/python3.8/site-packages/torchvision/models/detection/generalized_rcnn.py", line 99, in forward
    proposals, proposal_losses = self.rpn(images, features, targets)
  File "/home/choi/anaconda3/envs/headhunter/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/choi/hwang/workspace/HeadHunter/head_detection/models/fast_rcnn.py", line 495, in forward
    anchors = self.anchor_generator(images, features)
  File "/home/choi/anaconda3/envs/headhunter/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/choi/anaconda3/envs/headhunter/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py", line 147, in forward
    strides = [[torch.tensor(image_size[0] // g[0], dtype=torch.int64, device=device),
  File "/home/choi/anaconda3/envs/headhunter/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py", line 147, in <listcomp>
    strides = [[torch.tensor(image_size[0] // g[0], dtype=torch.int64, device=device),
KeyboardInterrupt
