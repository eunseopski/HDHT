Epoch: [1]  [    0/15000]  eta: 2:04:10  lr: 0.010000  loss: 1.5143 (1.5143)  loss_classifier: 0.7151 (0.7151)  loss_box_reg: 0.0152 (0.0152)  loss_objectness: 0.6921 (0.6921)  loss_rpn_box_reg: 0.0918 (0.0918)  time: 0.4967  data: 0.1524  max mem: 2548
/home/choi/anaconda3/envs/headhunter/lib/python3.8/site-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details.
  warnings.warn("The default behavior for interpolate/upsample with float scale_factor changed "
Traceback (most recent call last):
  File "train.py", line 193, in <module>
    train()
  File "train.py", line 184, in train
    train_one_epoch(model, optimizer, train_data_loader,
  File "/home/choi/hwang/workspace/HeadHunter/head_detection/vision/engine.py", line 62, in train_one_epoch
    losses.backward()
  File "/home/choi/anaconda3/envs/headhunter/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/choi/anaconda3/envs/headhunter/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
KeyboardInterrupt
